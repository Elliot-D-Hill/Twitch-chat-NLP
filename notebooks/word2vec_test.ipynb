{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corpus = ['This is the first document tested.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document testing?']\n",
    "\n",
    "# df = {'text':text, 'label':label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.839451  0.106467  0.226867  0.094032  0.465200  0.431445  0.510426   \n",
       "1  0.532837  0.308438  0.786720  0.799679  0.927000  0.316447  0.418269   \n",
       "2  0.086543  0.692698  0.443455  0.287400  0.063104  0.572081  0.315294   \n",
       "3  0.812719  0.270134  0.013555  0.129150  0.986392  0.189261  0.118908   \n",
       "4  0.341159  0.930880  0.181431  0.819185  0.874592  0.297166  0.408289   \n",
       "5  0.227163  0.485081  0.446012  0.727338  0.628730  0.805641  0.283428   \n",
       "6  0.333972  0.071765  0.213157  0.771068  0.127222  0.892340  0.331193   \n",
       "7  0.828520  0.775517  0.854969  0.428725  0.665224  0.551648  0.873191   \n",
       "8  0.536820  0.363695  0.377927  0.422454  0.088357  0.139211  0.756588   \n",
       "9  0.189815  0.209700  0.732198  0.690400  0.505873  0.319281  0.060560   \n",
       "\n",
       "         7         8         9   ...        20        21        22        23  \\\n",
       "0  0.287442  0.802281  0.502919  ...  0.057301  0.538852  0.014520  0.316467   \n",
       "1  0.499182  0.327764  0.779854  ...  0.678499  0.679109  0.305329  0.283338   \n",
       "2  0.996526  0.513555  0.621747  ...  0.297915  0.636239  0.144128  0.535058   \n",
       "3  0.157387  0.203973  0.153436  ...  0.087461  0.383570  0.392953  0.908965   \n",
       "4  0.725684  0.462028  0.263091  ...  0.144657  0.437032  0.735760  0.554012   \n",
       "5  0.930846  0.010210  0.837846  ...  0.061938  0.914034  0.893331  0.215567   \n",
       "6  0.324656  0.245926  0.561091  ...  0.968490  0.125212  0.998300  0.949676   \n",
       "7  0.219594  0.509980  0.663566  ...  0.663430  0.020256  0.535035  0.492159   \n",
       "8  0.998537  0.600271  0.694214  ...  0.479173  0.242784  0.831718  0.808427   \n",
       "9  0.592273  0.495222  0.865695  ...  0.207790  0.840276  0.503075  0.375558   \n",
       "\n",
       "         24        25        26        27        28        29  \n",
       "0  0.378941  0.940271  0.991968  0.014386  0.435970  0.113478  \n",
       "1  0.127421  0.196249  0.318858  0.642049  0.785235  0.258264  \n",
       "2  0.573573  0.650569  0.752787  0.210470  0.075599  0.501241  \n",
       "3  0.734421  0.806484  0.029717  0.959384  0.444344  0.299220  \n",
       "4  0.636760  0.774936  0.094739  0.573966  0.537256  0.571584  \n",
       "5  0.352606  0.177170  0.080709  0.959095  0.224790  0.721176  \n",
       "6  0.746048  0.119564  0.821920  0.847337  0.859117  0.135303  \n",
       "7  0.594935  0.273038  0.727263  0.137533  0.156578  0.589409  \n",
       "8  0.893740  0.591044  0.856981  0.094123  0.128430  0.003366  \n",
       "9  0.692601  0.146468  0.662492  0.216648  0.017409  0.712004  \n",
       "\n",
       "[10 rows x 30 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.839451</td>\n      <td>0.106467</td>\n      <td>0.226867</td>\n      <td>0.094032</td>\n      <td>0.465200</td>\n      <td>0.431445</td>\n      <td>0.510426</td>\n      <td>0.287442</td>\n      <td>0.802281</td>\n      <td>0.502919</td>\n      <td>...</td>\n      <td>0.057301</td>\n      <td>0.538852</td>\n      <td>0.014520</td>\n      <td>0.316467</td>\n      <td>0.378941</td>\n      <td>0.940271</td>\n      <td>0.991968</td>\n      <td>0.014386</td>\n      <td>0.435970</td>\n      <td>0.113478</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.532837</td>\n      <td>0.308438</td>\n      <td>0.786720</td>\n      <td>0.799679</td>\n      <td>0.927000</td>\n      <td>0.316447</td>\n      <td>0.418269</td>\n      <td>0.499182</td>\n      <td>0.327764</td>\n      <td>0.779854</td>\n      <td>...</td>\n      <td>0.678499</td>\n      <td>0.679109</td>\n      <td>0.305329</td>\n      <td>0.283338</td>\n      <td>0.127421</td>\n      <td>0.196249</td>\n      <td>0.318858</td>\n      <td>0.642049</td>\n      <td>0.785235</td>\n      <td>0.258264</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.086543</td>\n      <td>0.692698</td>\n      <td>0.443455</td>\n      <td>0.287400</td>\n      <td>0.063104</td>\n      <td>0.572081</td>\n      <td>0.315294</td>\n      <td>0.996526</td>\n      <td>0.513555</td>\n      <td>0.621747</td>\n      <td>...</td>\n      <td>0.297915</td>\n      <td>0.636239</td>\n      <td>0.144128</td>\n      <td>0.535058</td>\n      <td>0.573573</td>\n      <td>0.650569</td>\n      <td>0.752787</td>\n      <td>0.210470</td>\n      <td>0.075599</td>\n      <td>0.501241</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.812719</td>\n      <td>0.270134</td>\n      <td>0.013555</td>\n      <td>0.129150</td>\n      <td>0.986392</td>\n      <td>0.189261</td>\n      <td>0.118908</td>\n      <td>0.157387</td>\n      <td>0.203973</td>\n      <td>0.153436</td>\n      <td>...</td>\n      <td>0.087461</td>\n      <td>0.383570</td>\n      <td>0.392953</td>\n      <td>0.908965</td>\n      <td>0.734421</td>\n      <td>0.806484</td>\n      <td>0.029717</td>\n      <td>0.959384</td>\n      <td>0.444344</td>\n      <td>0.299220</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.341159</td>\n      <td>0.930880</td>\n      <td>0.181431</td>\n      <td>0.819185</td>\n      <td>0.874592</td>\n      <td>0.297166</td>\n      <td>0.408289</td>\n      <td>0.725684</td>\n      <td>0.462028</td>\n      <td>0.263091</td>\n      <td>...</td>\n      <td>0.144657</td>\n      <td>0.437032</td>\n      <td>0.735760</td>\n      <td>0.554012</td>\n      <td>0.636760</td>\n      <td>0.774936</td>\n      <td>0.094739</td>\n      <td>0.573966</td>\n      <td>0.537256</td>\n      <td>0.571584</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.227163</td>\n      <td>0.485081</td>\n      <td>0.446012</td>\n      <td>0.727338</td>\n      <td>0.628730</td>\n      <td>0.805641</td>\n      <td>0.283428</td>\n      <td>0.930846</td>\n      <td>0.010210</td>\n      <td>0.837846</td>\n      <td>...</td>\n      <td>0.061938</td>\n      <td>0.914034</td>\n      <td>0.893331</td>\n      <td>0.215567</td>\n      <td>0.352606</td>\n      <td>0.177170</td>\n      <td>0.080709</td>\n      <td>0.959095</td>\n      <td>0.224790</td>\n      <td>0.721176</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.333972</td>\n      <td>0.071765</td>\n      <td>0.213157</td>\n      <td>0.771068</td>\n      <td>0.127222</td>\n      <td>0.892340</td>\n      <td>0.331193</td>\n      <td>0.324656</td>\n      <td>0.245926</td>\n      <td>0.561091</td>\n      <td>...</td>\n      <td>0.968490</td>\n      <td>0.125212</td>\n      <td>0.998300</td>\n      <td>0.949676</td>\n      <td>0.746048</td>\n      <td>0.119564</td>\n      <td>0.821920</td>\n      <td>0.847337</td>\n      <td>0.859117</td>\n      <td>0.135303</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.828520</td>\n      <td>0.775517</td>\n      <td>0.854969</td>\n      <td>0.428725</td>\n      <td>0.665224</td>\n      <td>0.551648</td>\n      <td>0.873191</td>\n      <td>0.219594</td>\n      <td>0.509980</td>\n      <td>0.663566</td>\n      <td>...</td>\n      <td>0.663430</td>\n      <td>0.020256</td>\n      <td>0.535035</td>\n      <td>0.492159</td>\n      <td>0.594935</td>\n      <td>0.273038</td>\n      <td>0.727263</td>\n      <td>0.137533</td>\n      <td>0.156578</td>\n      <td>0.589409</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.536820</td>\n      <td>0.363695</td>\n      <td>0.377927</td>\n      <td>0.422454</td>\n      <td>0.088357</td>\n      <td>0.139211</td>\n      <td>0.756588</td>\n      <td>0.998537</td>\n      <td>0.600271</td>\n      <td>0.694214</td>\n      <td>...</td>\n      <td>0.479173</td>\n      <td>0.242784</td>\n      <td>0.831718</td>\n      <td>0.808427</td>\n      <td>0.893740</td>\n      <td>0.591044</td>\n      <td>0.856981</td>\n      <td>0.094123</td>\n      <td>0.128430</td>\n      <td>0.003366</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.189815</td>\n      <td>0.209700</td>\n      <td>0.732198</td>\n      <td>0.690400</td>\n      <td>0.505873</td>\n      <td>0.319281</td>\n      <td>0.060560</td>\n      <td>0.592273</td>\n      <td>0.495222</td>\n      <td>0.865695</td>\n      <td>...</td>\n      <td>0.207790</td>\n      <td>0.840276</td>\n      <td>0.503075</td>\n      <td>0.375558</td>\n      <td>0.692601</td>\n      <td>0.146468</td>\n      <td>0.662492</td>\n      <td>0.216648</td>\n      <td>0.017409</td>\n      <td>0.712004</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 30 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "import random\n",
    "end_value = 10\n",
    "dictinary_list = []\n",
    "for i in range(0, end_value, 1):\n",
    "    dictionary_data = {k: random.random() for k in range(30)}\n",
    "    dictinary_list.append(dictionary_data)\n",
    "\n",
    "df_final = pd.DataFrame.from_dict(dictinary_list)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "text = [' '.join([stemmer.stem(word) for word in tokenizer.tokenize(sentence)]) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 1 1 0 0 1 1 0 1]\n [0 2 0 1 0 1 0 1 0 1]\n [1 0 0 1 1 0 0 1 1 1]\n [0 1 1 1 0 0 1 1 0 1]]\n['and', 'document', 'first', 'is', 'one', 'second', 'test', 'the', 'third', 'this']\n  (0, 9)\t1\n  (0, 3)\t1\n  (0, 7)\t1\n  (0, 2)\t1\n  (0, 1)\t1\n  (0, 6)\t1\n  (1, 9)\t1\n  (1, 3)\t1\n  (1, 7)\t1\n  (1, 1)\t2\n  (1, 5)\t1\n  (2, 9)\t1\n  (2, 3)\t1\n  (2, 7)\t1\n  (2, 0)\t1\n  (2, 8)\t1\n  (2, 4)\t1\n  (3, 9)\t1\n  (3, 3)\t1\n  (3, 7)\t1\n  (3, 2)\t1\n  (3, 1)\t1\n  (3, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "print(X.toarray())\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-7245aca0d9bd>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-7245aca0d9bd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pd.DataFrame({\"username\":, \"channel\", \"dt_string\", \"comment\", \"sentiment\"})\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({\"username\", \"channel\", \"dt_string\", \"comment\", \"sentiment\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=25, n_iter=25, random_state=12)\n",
    "truncated_tfidf = svd.fit_transform(X)\n",
    "truncated_bag_of_words = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from transformers import GensimWord2VecVectorizer\n",
    "\n",
    "w2v = GensimWord2VecVectorizer(size=50, min_count=3, sg=1, alpha=0.025, iter=10)\n",
    "xgb = XGBClassifier(learning_rate=0.01, n_estimators=100, n_jobs=-1)\n",
    "w2v_xgb = Pipeline([\n",
    "    ('w2v', w2v), \n",
    "    ('xgb', xgb)\n",
    "])\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "w2v_xgb.fit(X_train, y_train)\n",
    "elapse = time.time() - start\n",
    "print('elapsed: ', elapse)\n",
    "w2v_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}